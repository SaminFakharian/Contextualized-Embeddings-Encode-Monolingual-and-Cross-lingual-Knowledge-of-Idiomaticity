{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"RuBERT_AllExpression_FT_(D_CF)_CLS.ipynb","provenance":[{"file_id":"1mqiyqQuBAg8GpRgf3bWjjkPh9GBlBGYl","timestamp":1617652382603}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"597356aab5c842f287fb3d467f394d87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_78f826f21bcc4cd290fcbf145b5356f6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d20bc17dd24a462184ecbd17fbb8082d","IPY_MODEL_00b44b05a7374aeca89e39f73c6a45d5"]}},"78f826f21bcc4cd290fcbf145b5356f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d20bc17dd24a462184ecbd17fbb8082d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f151b80a519242f7963383dfe149eb30","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":642,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":642,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c33e0fa9a354405b5ced2110c631752"}},"00b44b05a7374aeca89e39f73c6a45d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e1dd93a26d064d61bb18a6731f12ad62","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 642/642 [00:28&lt;00:00, 22.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9339fdcc30234daebde48f5826f81e45"}},"f151b80a519242f7963383dfe149eb30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c33e0fa9a354405b5ced2110c631752":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e1dd93a26d064d61bb18a6731f12ad62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9339fdcc30234daebde48f5826f81e45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d73bdf257f69433a9e3a0e26a471f3da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2cd4e08fd757497f87632e0058604c32","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a8ee401dfe93417faf8b9278c03eb8bd","IPY_MODEL_bdad98ccbc5f41499e00678c0240a6e2"]}},"2cd4e08fd757497f87632e0058604c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a8ee401dfe93417faf8b9278c03eb8bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_64f7dad87f65479dae4c1acf64c0b2d2","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":711456796,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":711456796,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_40e3080850634722b168784b5a2f4c05"}},"bdad98ccbc5f41499e00678c0240a6e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d436c0eba53241d8a6c20ee63f349bdd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 711M/711M [00:23&lt;00:00, 30.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79f1eed2a37249009ee726b26bbb1bba"}},"64f7dad87f65479dae4c1acf64c0b2d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"40e3080850634722b168784b5a2f4c05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d436c0eba53241d8a6c20ee63f349bdd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79f1eed2a37249009ee726b26bbb1bba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22fcbcad935a4d3b89ce3d392726c706":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06cb116024014a85b0baf4f1d07dd14b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d523046171424c08a6ebf90ac6792ff9","IPY_MODEL_09550ef07e7d422ba09eb6967aaa2f47"]}},"06cb116024014a85b0baf4f1d07dd14b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d523046171424c08a6ebf90ac6792ff9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fddfcefdd5d944488db91eba5cfc0730","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1649718,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1649718,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f669efe2c29548b0be3156fef75f855f"}},"09550ef07e7d422ba09eb6967aaa2f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8eb12283f9ce48259504baa9694dd119","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.65M/1.65M [00:00&lt;00:00, 3.84MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5f4b7e7544444db1b256cdd16273bf21"}},"fddfcefdd5d944488db91eba5cfc0730":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f669efe2c29548b0be3156fef75f855f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8eb12283f9ce48259504baa9694dd119":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5f4b7e7544444db1b256cdd16273bf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f481d1af87b420cb8cc2fea21139fae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2b3e01134e214573bcd7a1cdb2787200","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0093447d389741cf8ec4da9aa493b006","IPY_MODEL_60a4d50eafed4a74a9ac38c322968177"]}},"2b3e01134e214573bcd7a1cdb2787200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0093447d389741cf8ec4da9aa493b006":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e06b661158744c5a89136cfc5ada19e7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":112,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f303800d0a424e74a7bde963d2a77105"}},"60a4d50eafed4a74a9ac38c322968177":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f270e43455ec4df59e7705e7064c484c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 112/112 [00:01&lt;00:00, 109B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b0eab98d3084f8b82bd007f3b920e12"}},"e06b661158744c5a89136cfc5ada19e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f303800d0a424e74a7bde963d2a77105":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f270e43455ec4df59e7705e7064c484c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b0eab98d3084f8b82bd007f3b920e12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4fc8cababe114b5eac1cc12b8a27f7a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e47956a17e74a918e926be042025ee6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ba1c24009edc4d868db3db55f386a4bb","IPY_MODEL_84adfaeafa684837bfefa8334436297a"]}},"6e47956a17e74a918e926be042025ee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba1c24009edc4d868db3db55f386a4bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4d98936889d14ecfa1147738373d9dec","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eaf2b4f5e190452cafeb60a86e41e13e"}},"84adfaeafa684837bfefa8334436297a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_576630c2f33b4b1db1c626136f3fc328","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.00/2.00 [00:00&lt;00:00, 4.95B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd5c55fe09ad43ca9b157ed707afea66"}},"4d98936889d14ecfa1147738373d9dec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"eaf2b4f5e190452cafeb60a86e41e13e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"576630c2f33b4b1db1c626136f3fc328":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bd5c55fe09ad43ca9b157ed707afea66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69ZcIDFJny21","executionInfo":{"status":"ok","timestamp":1619788460792,"user_tz":180,"elapsed":5775,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"155eb93f-1f2e-4ba0-e526-703e7536fa49"},"source":["!pip install transformers==3.0.0"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 19.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.41.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.0.12)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 36.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 53.5MB/s \n","\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fL589BZSny29","executionInfo":{"status":"ok","timestamp":1619788468474,"user_tz":180,"elapsed":5617,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["import random\n","import os\n","import re\n","import math\n","import time\n","import datetime\n","import numpy as np\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","os.environ['PYTHONHASHSEED'] = str(seed_val)\n","import pylab as pl\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import gensim\n","from gensim.models.word2vec import Word2Vec\n","from gensim.models import Word2Vec\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from collections import Counter, defaultdict\n","\n","from sklearn import utils\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split,learning_curve, GridSearchCV, cross_val_score, StratifiedKFold,StratifiedShuffleSplit\n","from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n","\n","import torch\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","from tqdm import tqdm\n","tqdm.pandas(desc=\"progress-bar\")\n","\n","import transformers as tf\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AdamW\n","from transformers import AutoModel, BertTokenizerFast,BertModel,AutoTokenizer\n","from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n","%matplotlib inline\n","\n","from google.colab import drive\n","from google.colab import files"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JltYaDSny3D","executionInfo":{"status":"ok","timestamp":1619788468479,"user_tz":180,"elapsed":2632,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"c4808788-5af0-46a6-a400-2a26465ca9e1"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoHbFBfs-GYR","executionInfo":{"status":"ok","timestamp":1619788492144,"user_tz":180,"elapsed":22386,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"25121ffc-8b91-4512-c2c6-285dba4430a6"},"source":["drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU8FrRmEny3J","executionInfo":{"status":"ok","timestamp":1619789609776,"user_tz":180,"elapsed":663,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["russian_data=pd.read_excel('./drive/My Drive/Colab Notebooks/dataset/Russian Idioms/sentences_wiki_1404_w_300.xlsx')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","\n","# russian_data=russian_data.head(1400)\n","from sklearn.model_selection import train_test_split\n","\n","dev_train, dev_test = train_test_split(russian_data, test_size=0.25,shuffle=True,stratify=russian_data['label'])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WggCZzn_AQb","executionInfo":{"status":"ok","timestamp":1619789632505,"user_tz":180,"elapsed":289,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"a469af80-f2d4-40b8-ca84-eda978db0e73"},"source":["russian_data['label'].value_counts()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["I    421\n","L    354\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"4-CPccOZny3O","executionInfo":{"status":"ok","timestamp":1619788496279,"user_tz":180,"elapsed":275,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["dev_train['label'] = dev_train.label.map({'L':0, 'I':1})\n","# dev_train['isCanon'] = dev_train.isCanon.map({'Not':0, 'C':1})"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8goSr0tny3p","executionInfo":{"status":"ok","timestamp":1619788497401,"user_tz":180,"elapsed":795,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["dev_test['label'] = dev_test.label.map({'L':0, 'I':1})\n","# dev_test['isCanon'] = dev_test.isCanon.map({'Not':0, 'C':1})"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"qn89U3Jzny33","executionInfo":{"status":"ok","timestamp":1619788497402,"user_tz":180,"elapsed":461,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# test_train['label'] = test_train.label.map({'L':0, 'I':1})\n","# test_train['isCanon'] = test_train.isCanon.map({'Not':0, 'C':1})"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZ5GdSwzny4D","executionInfo":{"status":"ok","timestamp":1619788498194,"user_tz":180,"elapsed":271,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# test_test['label'] = test_test.label.map({'L':0, 'I':1})\n","# test_test['isCanon'] = test_test.isCanon.map({'Not':0, 'C':1})"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Akd77Vamny4H","executionInfo":{"status":"ok","timestamp":1619788498931,"user_tz":180,"elapsed":690,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# file_name=dev_train.fileName.unique().tolist()\n","# file_name"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWiZX4cJlA46","executionInfo":{"status":"ok","timestamp":1619788499077,"user_tz":180,"elapsed":402,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# dev_train=test_train\n","# dev_test=test_test"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Ntl98yvlYFB","executionInfo":{"status":"ok","timestamp":1619788500177,"user_tz":180,"elapsed":314,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nx_1bhFlsVzB","executionInfo":{"status":"ok","timestamp":1619788501274,"user_tz":180,"elapsed":981,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    # pred_flat = np.argmax(preds, axis=1).flatten()\n","    # labels_flat = labels.flatten()\n","    return np.sum(preds == labels.numpy()) / len(labels)\n","\n","def flat_accuracy_num(preds, labels):\n","    # pred_flat = np.argmax(preds, axis=1).flatten()\n","    # labels_flat = labels.flatten()\n","    return np.sum(preds == labels.numpy())"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"SahR-sZygfYF","executionInfo":{"status":"ok","timestamp":1619788501275,"user_tz":180,"elapsed":592,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["hidden_data=[]\n","hidden_dat=[]\n","cls_hs_input=[]\n","class Classifier(nn.Module):\n","\n","    def __init__(self, bert):\n","        super(Classifier, self).__init__()\n","        self.bert = bert\n","        self.dropout = nn.Dropout(0.5)\n","        # relu activation function\n","        self.relu =  nn.ReLU()\n","        # dense layer 1\n","        self.fc1 = nn.Linear(768,512)\n","        # dense layer 2 (Output layer)\n","        self.fc2 = nn.Linear(512,2)\n","        #softmax activation function\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask,stage):\n","      #pass the inputs to the model  \n","        output=self.bert(sent_id, attention_mask=mask)\n","        # print(output[0].shape)\n","        # print(output[1].shape)\n","        # print(output[2].shape)\n","\n","        # output = output[2]\n","        \n","        cls_hs=output[0][:,0,:]\n","\n","        # x = self.fc1(cls_hs)\n","        # x = self.relu(x)\n","        # x = self.dropout(x)\n","        # # output layer\n","        # x = self.fc2(x)\n","        # # apply softmax activation\n","        # x = self.softmax(x)\n","\n","        if stage=='test':\n","            cls_hs_input.append(cls_hs.detach().cpu().numpy())\n","        x = self.fc1(cls_hs)\n","        if stage=='test':\n","            hidden_dat.append(x.detach().cpu().numpy())\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        # output layer\n","        if stage=='test':\n","            hidden_data.append(x.detach().cpu().numpy())\n","        x = self.fc2(x)\n","        # apply softmax activation\n","        x = self.softmax(x)\n","        return x"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"41XaVN4ng6sj","executionInfo":{"status":"ok","timestamp":1619788501486,"user_tz":180,"elapsed":463,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","#   i=0\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    # print(i)\n","    # progress update after every 50 batches.\n","    if step % 10 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask,'train')\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","    total_steps = len(train_dataloader) * epochs\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                        num_warmup_steps = 0, # Default value in run_glue.py\n","                                                        num_training_steps = total_steps)\n","    # update parameters\n","    optimizer.step()\n","    scheduler.step()\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","    # i+=1\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOW3mvSig6vy","executionInfo":{"status":"ok","timestamp":1619788501751,"user_tz":180,"elapsed":325,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","#   i=0  \n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    # print(i)\n","    # Progress update every 50 batches.\n","    if step % 10 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","    #   elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","    #   print(\"val_loop:\",i)\n","      # model predictions\n","      preds = model(sent_id, mask,'evaluate')\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","    # i+=1\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zcqb-NgbO4Vq","executionInfo":{"status":"ok","timestamp":1619788502829,"user_tz":180,"elapsed":442,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["random_seeds=[68,96,20,53,91,7,42,14,24,67]"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"dxn9T5xp4Cgx","executionInfo":{"status":"ok","timestamp":1619788503619,"user_tz":180,"elapsed":337,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"8704714b-89e3-4118-b26d-46d617a74492"},"source":["dev_train"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mwe</th>\n","      <th>label</th>\n","      <th>sentence</th>\n","      <th>par</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>165</th>\n","      <td>на чемоданах</td>\n","      <td>1</td>\n","      <td>— художественный фильм «Джек и Джил: Любовь н...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>516</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>куропатчатое — у петухов шейное оперение тёмно...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>ы Гернет. С юных лет воспитывался в атмосфере ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>по барабану</td>\n","      <td>1</td>\n","      <td>и лишает Будилову невинности, после чего перес...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>на ножах</td>\n","      <td>1</td>\n","      <td>по ложному обвинению оказывается в тюрьме, а ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>739</th>\n","      <td>второй дом</td>\n","      <td>0</td>\n","      <td>16 ноября 2008 года женился на Мерхавит Соломо...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>502</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>Песни « » и «    » из нового альбома с блеском...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>719</th>\n","      <td>второй дом</td>\n","      <td>1</td>\n","      <td>Первым владельцем дома был  \"Пашков, Пётр Егор...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>поставить точку</td>\n","      <td>1</td>\n","      <td>Невышедший роман должен был называться «Дочь А...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>770</th>\n","      <td>замести следы</td>\n","      <td>1</td>\n","      <td>Однако последнее ограбление повлекло за собой ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>581 rows × 4 columns</p>\n","</div>"],"text/plain":["                 mwe  ...  par\n","165     на чемоданах  ...    3\n","516        с блеском  ...    2\n","507        с блеском  ...    3\n","428      по барабану  ...    2\n","212         на ножах  ...    3\n","..               ...  ...  ...\n","739       второй дом  ...    2\n","502        с блеском  ...    3\n","719       второй дом  ...    2\n","398  поставить точку  ...    2\n","770    замести следы  ...    2\n","\n","[581 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":687,"referenced_widgets":["597356aab5c842f287fb3d467f394d87","78f826f21bcc4cd290fcbf145b5356f6","d20bc17dd24a462184ecbd17fbb8082d","00b44b05a7374aeca89e39f73c6a45d5","f151b80a519242f7963383dfe149eb30","6c33e0fa9a354405b5ced2110c631752","e1dd93a26d064d61bb18a6731f12ad62","9339fdcc30234daebde48f5826f81e45","d73bdf257f69433a9e3a0e26a471f3da","2cd4e08fd757497f87632e0058604c32","a8ee401dfe93417faf8b9278c03eb8bd","bdad98ccbc5f41499e00678c0240a6e2","64f7dad87f65479dae4c1acf64c0b2d2","40e3080850634722b168784b5a2f4c05","d436c0eba53241d8a6c20ee63f349bdd","79f1eed2a37249009ee726b26bbb1bba","22fcbcad935a4d3b89ce3d392726c706","06cb116024014a85b0baf4f1d07dd14b","d523046171424c08a6ebf90ac6792ff9","09550ef07e7d422ba09eb6967aaa2f47","fddfcefdd5d944488db91eba5cfc0730","f669efe2c29548b0be3156fef75f855f","8eb12283f9ce48259504baa9694dd119","5f4b7e7544444db1b256cdd16273bf21","0f481d1af87b420cb8cc2fea21139fae","2b3e01134e214573bcd7a1cdb2787200","0093447d389741cf8ec4da9aa493b006","60a4d50eafed4a74a9ac38c322968177","e06b661158744c5a89136cfc5ada19e7","f303800d0a424e74a7bde963d2a77105","f270e43455ec4df59e7705e7064c484c","0b0eab98d3084f8b82bd007f3b920e12","4fc8cababe114b5eac1cc12b8a27f7a0","6e47956a17e74a918e926be042025ee6","ba1c24009edc4d868db3db55f386a4bb","84adfaeafa684837bfefa8334436297a","4d98936889d14ecfa1147738373d9dec","eaf2b4f5e190452cafeb60a86e41e13e","576630c2f33b4b1db1c626136f3fc328","bd5c55fe09ad43ca9b157ed707afea66"]},"id":"Z3eI0_m3dqFL","executionInfo":{"status":"error","timestamp":1619788566734,"user_tz":180,"elapsed":39398,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"b3518f65-174a-4c81-ce70-3b74cd56e8e0"},"source":["################################################################################\n","#################################### all together ##############################\n","################################################################################\n","temp_train=pd.DataFrame()\n","temp_validation=pd.DataFrame()\n","train_loss=[]\n","lr_clf_scores_dict={}\n","svc_clf_scores_dict={}\n","avg_acc=[]\n","val_result = []\n","by_expression=pd.DataFrame(columns=['rand_var','file','mwe','label','prediction'])\n","# learning_rate_range=[2e-5,3e-5,5e-5]\n","# epoch_range=[2,3,4]\n","# batch_size_range=[8,16,32]\n","\n","learning_rate_range=[3e-5]\n","epoch_range=[4]\n","batch_size_range=[8]\n","\n","i=0\n","run=0\n","final_result_df=pd.DataFrame()\n","final_result_df_le=pd.DataFrame()\n","random_seeds=[68,96,20,53,91,72,42,14,24,67]\n","# random_seeds=[42]\n","\n","for rand_var in random_seeds:\n","    for er in epoch_range:\n","        for lrr in learning_rate_range:\n","          for bsr in batch_size_range:\n","            for ds in range(0,1):\n","                print(run)\n","                run+=1\n","                print(\"-------------------------------------------------------\")\n","                print(\"Start processing for: \",ds)\n","                temp_train=dev_train#[dev_train.fileName==ds]\n","                temp_test=dev_test#[dev_test.fileName==ds]\n","                \n","                seed_value = rand_var\n","\n","                # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n","                import os\n","                os.environ['PYTHONHASHSEED']=str(seed_value)\n","                # 2. Set `python` built-in pseudo-random generator at a fixed value\n","                import random\n","                random.seed(seed_value)\n","                # 3. Set `numpy` pseudo-random generator at a fixed value\n","                import numpy as np\n","                np.random.seed(seed_value)\n","                import torch\n","                torch.manual_seed(seed_value)\n","                torch.cuda.manual_seed_all(seed_value)\n","                torch.backends.cudnn.deterministic = True\n","                torch.backends.cudnn.benchmark = False\n","\n","\n","                # bert = AutoModel.from_pretrained('bert-base-uncased')\n","                bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased')\n","                # Load the BERT tokenizer\n","                tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n","                # get length of all the messages in the train set\n","                seq_len = [len(i.split()) for i in dev_train['sentence']]\n","                # pd.Series(seq_len).hist(bins = 30)\n","                max_seq_len = 0\n","                max_len = max_seq_len\n","                # For every sentence...\n","                for sent in temp_train['sentence']:\n","                    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","                    # print(sent)\n","                    train_input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","                    # print(train_input_ids)\n","                    # Update the maximum sentence length.\n","                    max_seq_len = max(max_seq_len, len(train_input_ids))\n","                # print(max)\n","                print(max_seq_len)\n","                max_seq_len=256\n","                train_text, val_text, train_labels, val_labels = train_test_split(temp_train['sentence'], temp_train['label'], \n","                                                                        random_state=2018, \n","                                                                        test_size=0.2, \n","                                                                        stratify=temp_train['label'])\n","\n","                # we will use temp_text and temp_labels to create validation and test set\n","                test_text =temp_test['sentence']\n","                test_labels =temp_test['label']\n","                # tokenize and encode sequences in the training set\n","                tokens_train = tokenizer.batch_encode_plus(\n","                    train_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","                # print(tokens_train)\n","                # tokenize and encode sequences in the validation set\n","                tokens_val = tokenizer.batch_encode_plus(\n","                    val_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","\n","                # tokenize and encode sequences in the test set\n","                tokens_test = tokenizer.batch_encode_plus(\n","                    test_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","                # for train set\n","                train_seq = torch.tensor(tokens_train['input_ids'])\n","                train_mask = torch.tensor(tokens_train['attention_mask'])\n","                train_y = torch.tensor(train_labels.tolist())\n","\n","                # for validation set\n","                val_seq = torch.tensor(tokens_val['input_ids'])\n","                val_mask = torch.tensor(tokens_val['attention_mask'])\n","                val_y = torch.tensor(val_labels.tolist())\n","\n","                # for test set\n","                test_seq = torch.tensor(tokens_test['input_ids'])\n","                test_mask = torch.tensor(tokens_test['attention_mask'])\n","                test_y = torch.tensor(test_labels.tolist())\n","\n","                #define a batch size\n","                batch_size = bsr\n","                # wrap tensors\n","                train_data = TensorDataset(train_seq, train_mask, train_y)\n","                # sampler for sampling the data during training\n","                train_sampler = RandomSampler(train_data)\n","                # dataLoader for train set\n","                train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","                # wrap tensors\n","                val_data = TensorDataset(val_seq, val_mask, val_y)\n","                # sampler for sampling the data during training\n","                val_sampler = SequentialSampler(val_data)\n","                # dataLoader for validation set\n","                val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n","                # CF_arr=torch.tensor(temp_train.isCanon.to_numpy())\n","                # CF_arr=torch.reshape(CF_arr,(-1,1))\n","                # CF_arr=CF_arr.to(device)\n","                # CF_test_arr=torch.tensor(temp_test.isCanon.to_numpy())\n","                # CF_test_arr=torch.reshape(CF_test_arr,(-1,1))\n","                # CF_test_arr=CF_arr.to(device)\n","\n","                training_stats = []\n","                training_stats_le = []\n","                # pass the pre-trained BERT to our define architecture\n","                model = Classifier(bert)\n","                # push the model to GPU\n","                model = model.to(device)\n","                # optimizer from hugging face transformer\n","                # define the optimizer\n","                optimizer = AdamW(model.parameters(), lr = lrr)\n","                #compute the class weights\n","                class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","                # convert class weights to tensor\n","                weights= torch.tensor(class_wts,dtype=torch.float)\n","                weights = weights.to(device)\n","\n","                # loss function\n","                cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","                # number of training epochs\n","                epochs = er\n","                # set initial loss to infinite\n","                best_valid_loss = float('inf')\n","\n","                # empty lists to store training and validation loss of each epoch\n","                train_losses=[]\n","                valid_losses=[]\n","\n","                #for each epoch\n","                for epoch in range(epochs):\n","                    \n","                    print('\\nEpoch {:}/{:}'.format(epoch + 1, epochs))\n","                    \n","                    #train model\n","                    train_loss, _ = train()\n","                    \n","                    #evaluate model\n","                    valid_loss, _ = evaluate()\n","                    \n","                    #save the best model\n","                    if valid_loss < best_valid_loss:\n","                        best_valid_loss = valid_loss\n","                        torch.save(model.state_dict(), 'saved_weights.pt')\n","                    \n","                    # append training and validation loss\n","                    train_losses.append(train_loss)\n","                    valid_losses.append(valid_loss)\n","                    print(f'\\nTraining Loss: {train_loss:10.4f}')\n","                    print(f'Validation Loss: {valid_loss:10.4f}')\n","                    \n","                # get predictions for test data\n","                with torch.no_grad():\n","                    preds = model(test_seq.to(device), test_mask.to(device),'test')\n","                    preds = preds.detach().cpu().numpy()\n","                # model's performance\n","                preds = np.argmax(preds, axis = 1)\n","\n","                # print(classification_report(test_y, preds))\n","                total_eval_accuracy_num = 0\n","                total_eval_accuracy = 0\n","                total_eval_accuracy = flat_accuracy(preds, test_y)\n","                total_eval_accuracy_num = flat_accuracy_num(preds, test_y)\n","                print(\"Number of True Prediction: {0:10.4f}\".format(total_eval_accuracy_num))\n","                # avg_val_accuracy = total_eval_accuracy / len(test_y)\n","                print(\"Accuracy: {0:10.4f}\".format(total_eval_accuracy))\n","                \n","                # val_result.append((rand_var,total_eval_accuracy, total_eval_accuracy_num, len(test_y),ds, lrr, er, bsr))\n","                quick_temp=pd.DataFrame(columns=['rand_var','file','mwe','label','prediction'])\n","                quick_temp['rand_var']=[rand_var]*len(preds)\n","                quick_temp['file']=[ds]*len(preds)                \n","                quick_temp['mwe']=temp_test['mwe'].tolist()\n","                quick_temp['label']=temp_test['label'].tolist()\n","                quick_temp['prediction']=preds\n","                by_expression=by_expression.append(quick_temp)\n","\n","                TN = 0\n","                FN = 0\n","                TP = 0\n","                FP = 0       \n","                CM = confusion_matrix(test_y, preds)\n","                report= classification_report(test_y, preds, digits=3,output_dict=True)\n","                df = pd.DataFrame(report).transpose()\n","\n","                TN = CM[0][0]\n","                FN = CM[1][0]\n","                TP = CM[1][1]\n","                FP = CM[0][1]\n","\n","                if ((TP+FP) == 0):\n","                    precision = 0.0\n","                else:\n","                    precision=TP/(TP+FP)\n","                if ((TP+FN) == 0):\n","                    recall = 0.0\n","                else:\n","                    recall=TP/(TP+FN)\n","                if (precision+recall > 0 ):\n","                    f1 = (2.0*precision*recall)/(precision+recall)\n","                else:\n","                    f1 = 0.0\n","\n","                precision_0=report['0']['precision']\n","                recall_0=report['0']['recall']\n","                f1_0=report['0']['f1-score']\n","                support_0=report['0']['support']\n","                precision_1=report['1']['precision']\n","                recall_1=report['1']['recall']\n","                f1_1=report['1']['f1-score']\n","                support_1=report['1']['support']\n","                macro_avg_f1=report['macro avg']['f1-score']\n","                macro_avg_precision=report['macro avg']['precision']\n","                macro_avg_recall=report['macro avg']['recall']\n","                macro_avg_support=report['macro avg']['support']\n","                weighted_avg_f1=report['weighted avg']['f1-score']\n","                weighted_avg_precision=report['weighted avg']['precision']\n","                weighted_avg_recall=report['weighted avg']['recall']\n","                weighted_avg_support=report['weighted avg']['support']\n","                val_result.append((rand_var,total_eval_accuracy, total_eval_accuracy_num, len(test_y),\n","                                    TN,FN,TP,FP,\n","                                    precision_0,recall_0,f1_0,support_0,\n","                                    precision_1,recall_1,f1_1,support_1,\n","                                    macro_avg_f1,macro_avg_precision,macro_avg_recall,macro_avg_support,\n","                                    weighted_avg_f1,weighted_avg_precision,weighted_avg_recall,weighted_avg_support,\n","                                    ds, lrr, er, bsr))\n","                print('DONE.')\n","validation_df=pd.DataFrame(val_result,columns=['rand_var','accuracy', 'true_labels', 'all_labels',\n","                                               'TN','FN','TP','FP',\n","                                                'precision_literal','recall_literal','f1_literal','support_literal',\n","                                                'precision_idiomatic','recall_idiomatic','f1_idiomatic','support_idiomatic',\n","                                                'macro_avg_f1','macro_avg_precision','macro_avg_recall','macro_avg_support',\n","                                                'weighted_avg_f1','weighted_avg_precision','weighted_avg_recall','weighted_avg_support',\n","                                               'file', 'lr', 'e', 'b'])\n","\n","validation_df.to_excel('BERT-AE-W300-Wiki-randomseeds.xlsx',index=False)\n","files.download('BERT-AE-W300-Wiki-randomseeds.xlsx')\n","\n","# expression_df=pd.DataFrame(by_expression,columns=['mwe','label', 'prediction'])\n","# by_expression.to_excel('BERT-AE-W-Wiki-Expression.xlsx',index=False)\n","# files.download('BERT-AE-W-Wiki-Expression.xlsx') "],"execution_count":19,"outputs":[{"output_type":"stream","text":["0\n","-------------------------------------------------------\n","Start processing for:  0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"597356aab5c842f287fb3d467f394d87","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d73bdf257f69433a9e3a0e26a471f3da","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456796.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22fcbcad935a4d3b89ce3d392726c706","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0f481d1af87b420cb8cc2fea21139fae","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4fc8cababe114b5eac1cc12b8a27f7a0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2.0, style=ProgressStyle(description_wi…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","234\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-0e888ab597ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# push the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0;31m# optimizer from hugging face transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;31m# define the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nc5Xa7KVMMdT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LgzYXdzVoAq"},"source":["# from sklearn.manifold import TSNE\n","\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# dev_train=test_train\n","# dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(5, 3,figsize=(25,30))\n","# fig.suptitle('MWEs')\n","# i=0\n","# t= TSNE(learning_rate=20)\n","# mwe_list=temp_test.mwe.unique()\n","# palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# for m,ax in zip(mwe_list,axes.flatten()[:15]):\n","#     df=pd.DataFrame()\n","#     df['label']=temp_test[temp_test.mwe==m]['label']\n","#     tsne_features=t.fit_transform(hidden_data[i])\n","#     df['x']=tsne_features[:,0]\n","#     df['y']=tsne_features[:,1]\n","#     sns.scatterplot(ax=ax, x=\"x\",y=\"y\",hue='label',data=df,palette=palette).set_title(m,fontsize=16)\n","#     i+=1\n","\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37Wmhxu4dUB_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZ1H6Xy7qal2"},"source":["# from sklearn.manifold import TSNE\n","# all_hidden_data=[]\n","# for i in range(0,10):\n","#     for j in range(len(hidden_data[i])):\n","#         all_hidden_data.append(hidden_data[i][j].tolist())\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# # test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# # test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# # dev_train=test_train\n","# # dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(1, 1,figsize=(15,15))\n","# t= TSNE(learning_rate=50)\n","# mwe_list=temp_test.mwe.unique()\n","# palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# df=pd.DataFrame()\n","# df['label']=temp_test['label']\n","# tsne_features=t.fit_transform(all_hidden_data)\n","# df['x']=tsne_features[:,0]\n","# df['y']=tsne_features[:,1]\n","# sns.scatterplot(ax= axes,x=\"x\",y=\"y\",hue='label',data=df,palette=palette).set_title('AllData',fontsize=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFoO9jW4qUR_"},"source":["# from sklearn.manifold import TSNE\n","# all_hidden_data=[]\n","# for i in range(0,10):\n","#     for j in range(len(hidden_data[i])):\n","#         all_hidden_data.append(hidden_data[i][j].tolist())\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# dev_train=test_train\n","# dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(1, 1,figsize=(15,15))\n","# t= TSNE(learning_rate=50)\n","# mwe_list=temp_test.mwe.unique()\n","# # palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# df=pd.DataFrame()\n","# df['label']=temp_test['label']\n","# df['mwe']=temp_test['mwe']\n","\n","# tsne_features=t.fit_transform(all_hidden_data)\n","# df['x']=tsne_features[:,0]\n","# df['y']=tsne_features[:,1]\n","# sns.scatterplot(ax= axes,x=\"x\",y=\"y\",hue='mwe',data=df).set_title('AllData',fontsize=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n7WMFzDYtLoO"},"source":[""],"execution_count":null,"outputs":[]}]}