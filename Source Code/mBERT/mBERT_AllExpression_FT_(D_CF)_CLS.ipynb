{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"mBERT_AllExpression_FT_(D_CF)_CLS.ipynb","provenance":[{"file_id":"1oSbwAos-mD45VtOHgOjB7rZib25qJCO1","timestamp":1617681021228},{"file_id":"1mqiyqQuBAg8GpRgf3bWjjkPh9GBlBGYl","timestamp":1617652382603}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"1372baa745904245b09d8018aaf7cf30":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_be7e4ac4e5f546b0af3210c8abed2807","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bc0023925f80467e96dda4deb5026573","IPY_MODEL_c80205149f7c457981ac05d93834d2f2"]}},"be7e4ac4e5f546b0af3210c8abed2807":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bc0023925f80467e96dda4deb5026573":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8516c7266f8841a096d61eece52a6a7e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89fb2f1ab5c245908c53786beb97673e"}},"c80205149f7c457981ac05d93834d2f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1f544041d87549c2a4e85d5b413578c4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:01&lt;00:00, 360B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bef18cc12a194fe39799264692378d21"}},"8516c7266f8841a096d61eece52a6a7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"89fb2f1ab5c245908c53786beb97673e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f544041d87549c2a4e85d5b413578c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bef18cc12a194fe39799264692378d21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d68fca4be39b46e1a5a46e1caaac71ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f3cc79fda75d4e30b63cb86cff75a4eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c6640dcae7604befb2a184bb22f81de3","IPY_MODEL_2f1a9865e3f1408e836e7b9f5b754a6c"]}},"f3cc79fda75d4e30b63cb86cff75a4eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6640dcae7604befb2a184bb22f81de3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_db05771ee82348a188f9f7c798c2f878","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38eb6ba3c3624081a4e4c634dc9008d5"}},"2f1a9865e3f1408e836e7b9f5b754a6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_35854e2516e841aca52cae7bf3b9dedb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [01:02&lt;00:00, 11.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3cd41446e56047b883f9b3f9b1c2c929"}},"db05771ee82348a188f9f7c798c2f878":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"38eb6ba3c3624081a4e4c634dc9008d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35854e2516e841aca52cae7bf3b9dedb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3cd41446e56047b883f9b3f9b1c2c929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"50a1dfd2dfb14624b8b823c6d46d8c56":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ba2e2559ccd24e588a537e2163412e16","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c70750e71a764678afd1be2db91ea6bd","IPY_MODEL_b0f2a5c0f2dd4e8aa73ef809ddbf25f5"]}},"ba2e2559ccd24e588a537e2163412e16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c70750e71a764678afd1be2db91ea6bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f94bce417e634843ad6ca532a58061e6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fd85e4abc7d64f2b92f8aa2e0704c313"}},"b0f2a5c0f2dd4e8aa73ef809ddbf25f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e166a1bb7c88464fae8808e6aefa6c94","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:01&lt;00:00, 721kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_51ad507babb54614b68108fc4b2665f4"}},"f94bce417e634843ad6ca532a58061e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fd85e4abc7d64f2b92f8aa2e0704c313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e166a1bb7c88464fae8808e6aefa6c94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"51ad507babb54614b68108fc4b2665f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69ZcIDFJny21","executionInfo":{"status":"ok","timestamp":1619790994312,"user_tz":180,"elapsed":6609,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"07d9c503-99c2-4b3e-ffd9-b41cc49a0959"},"source":["!pip install transformers==3.0.0"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (1.19.5)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 37.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (2.23.0)\n","Collecting tokenizers==0.8.0-rc4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 50.9MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.0) (4.41.1)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 46.9MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.0) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.0) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.0) (1.24.3)\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fL589BZSny29","executionInfo":{"status":"ok","timestamp":1619790999449,"user_tz":180,"elapsed":9843,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["import random\n","import os\n","import re\n","import math\n","import time\n","import datetime\n","import numpy as np\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","os.environ['PYTHONHASHSEED'] = str(seed_val)\n","import pylab as pl\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import gensim\n","from gensim.models.word2vec import Word2Vec\n","from gensim.models import Word2Vec\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from collections import Counter, defaultdict\n","\n","from sklearn import utils\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.model_selection import train_test_split,learning_curve, GridSearchCV, cross_val_score, StratifiedKFold,StratifiedShuffleSplit\n","from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n","\n","import torch\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, random_split\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","from tqdm import tqdm\n","tqdm.pandas(desc=\"progress-bar\")\n","\n","import transformers as tf\n","from transformers import get_linear_schedule_with_warmup\n","from transformers import AdamW\n","from transformers import AutoModel, BertTokenizerFast,BertModel,AutoTokenizer,BertTokenizer\n","from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n","%matplotlib inline\n","\n","from google.colab import drive\n","from google.colab import files"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1JltYaDSny3D","executionInfo":{"status":"ok","timestamp":1619790999455,"user_tz":180,"elapsed":8582,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"73806537-4b8d-4823-a6e0-5ed57d461f7b"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoHbFBfs-GYR","executionInfo":{"status":"ok","timestamp":1619791024745,"user_tz":180,"elapsed":28975,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"4f72dcb1-0b8a-44b8-ec99-f6a38c4fcb54"},"source":["drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU8FrRmEny3J","executionInfo":{"status":"ok","timestamp":1619791029314,"user_tz":180,"elapsed":2955,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["russian_data=pd.read_excel('./drive/My Drive/Colab Notebooks/dataset/Russian Idioms/sentences_wiki_1404_w_300.xlsx')\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# russian_data=russian_data.head(1400)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEugEJfalx-x","executionInfo":{"status":"ok","timestamp":1619791032619,"user_tz":180,"elapsed":1467,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","dev_train, dev_test = train_test_split(russian_data, test_size=0.25,shuffle=True,stratify=russian_data['label'])"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"jsJwDXOrGzjn","executionInfo":{"status":"ok","timestamp":1619791666619,"user_tz":180,"elapsed":863,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"c5e83f55-4fef-4d46-f48e-667946296a2e"},"source":["dev_train"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mwe</th>\n","      <th>label</th>\n","      <th>sentence</th>\n","      <th>par</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>165</th>\n","      <td>на чемоданах</td>\n","      <td>1</td>\n","      <td>— художественный фильм «Джек и Джил: Любовь н...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>516</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>куропатчатое — у петухов шейное оперение тёмно...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>507</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>ы Гернет. С юных лет воспитывался в атмосфере ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>428</th>\n","      <td>по барабану</td>\n","      <td>1</td>\n","      <td>и лишает Будилову невинности, после чего перес...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>на ножах</td>\n","      <td>1</td>\n","      <td>по ложному обвинению оказывается в тюрьме, а ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>739</th>\n","      <td>второй дом</td>\n","      <td>0</td>\n","      <td>16 ноября 2008 года женился на Мерхавит Соломо...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>502</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>Песни « » и «    » из нового альбома с блеском...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>719</th>\n","      <td>второй дом</td>\n","      <td>1</td>\n","      <td>Первым владельцем дома был  \"Пашков, Пётр Егор...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>398</th>\n","      <td>поставить точку</td>\n","      <td>1</td>\n","      <td>Невышедший роман должен был называться «Дочь А...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>770</th>\n","      <td>замести следы</td>\n","      <td>1</td>\n","      <td>Однако последнее ограбление повлекло за собой ...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>581 rows × 4 columns</p>\n","</div>"],"text/plain":["                 mwe  ...  par\n","165     на чемоданах  ...    3\n","516        с блеском  ...    2\n","507        с блеском  ...    3\n","428      по барабану  ...    2\n","212         на ножах  ...    3\n","..               ...  ...  ...\n","739       второй дом  ...    2\n","502        с блеском  ...    3\n","719       второй дом  ...    2\n","398  поставить точку  ...    2\n","770    замести следы  ...    2\n","\n","[581 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"4-CPccOZny3O","executionInfo":{"status":"ok","timestamp":1619791039411,"user_tz":180,"elapsed":1052,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["dev_train['label'] = dev_train.label.map({'L':0, 'I':1})\n","# dev_train['isCanon'] = dev_train.isCanon.map({'Not':0, 'C':1})"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"i8goSr0tny3p","executionInfo":{"status":"ok","timestamp":1619791041358,"user_tz":180,"elapsed":1114,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["dev_test['label'] = dev_test.label.map({'L':0, 'I':1})\n","# dev_test['isCanon'] = dev_test.isCanon.map({'Not':0, 'C':1})"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"qn89U3Jzny33"},"source":["test_train['label'] = test_train.label.map({'L':0, 'I':1})\n","test_train['isCanon'] = test_train.isCanon.map({'Not':0, 'C':1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZ5GdSwzny4D"},"source":["test_test['label'] = test_test.label.map({'L':0, 'I':1})\n","test_test['isCanon'] = test_test.isCanon.map({'Not':0, 'C':1})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Akd77Vamny4H"},"source":["# file_name=dev_train.fileName.unique().tolist()\n","# file_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GWiZX4cJlA46"},"source":["dev_train=test_train\n","dev_test=test_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Ntl98yvlYFB","executionInfo":{"status":"ok","timestamp":1619791045292,"user_tz":180,"elapsed":1375,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"nx_1bhFlsVzB","executionInfo":{"status":"ok","timestamp":1619791056559,"user_tz":180,"elapsed":735,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    # pred_flat = np.argmax(preds, axis=1).flatten()\n","    # labels_flat = labels.flatten()\n","    return np.sum(preds == labels.numpy()) / len(labels)\n","\n","def flat_accuracy_num(preds, labels):\n","    # pred_flat = np.argmax(preds, axis=1).flatten()\n","    # labels_flat = labels.flatten()\n","    return np.sum(preds == labels.numpy())"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"SahR-sZygfYF","executionInfo":{"status":"ok","timestamp":1619791058628,"user_tz":180,"elapsed":1180,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["hidden_data=[]\n","hidden_dat=[]\n","cls_hs_input=[]\n","class Classifier(nn.Module):\n","\n","    def __init__(self, bert):\n","        super(Classifier, self).__init__()\n","        self.bert = bert\n","        self.dropout = nn.Dropout(0.5)\n","        # relu activation function\n","        self.relu =  nn.ReLU()\n","        # dense layer 1\n","        self.fc1 = nn.Linear(768,512)\n","        # dense layer 2 (Output layer)\n","        self.fc2 = nn.Linear(512,2)\n","        #softmax activation function\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask,stage):\n","      #pass the inputs to the model  \n","        output=self.bert(sent_id, attention_mask=mask)\n","        # print(output[0].shape)\n","        # print(output[1].shape)\n","        # print(output[2].shape)\n","\n","        # output = output[2]\n","        \n","        cls_hs=output[0][:,0,:]\n","\n","        # x = self.fc1(cls_hs)\n","        # x = self.relu(x)\n","        # x = self.dropout(x)\n","        # # output layer\n","        # x = self.fc2(x)\n","        # # apply softmax activation\n","        # x = self.softmax(x)\n","\n","        if stage=='test':\n","            cls_hs_input.append(cls_hs.detach().cpu().numpy())\n","        x = self.fc1(cls_hs)\n","        if stage=='test':\n","            hidden_dat.append(x.detach().cpu().numpy())\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        # output layer\n","        if stage=='test':\n","            hidden_data.append(x.detach().cpu().numpy())\n","        x = self.fc2(x)\n","        # apply softmax activation\n","        x = self.softmax(x)\n","        return x"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"41XaVN4ng6sj","executionInfo":{"status":"ok","timestamp":1619791061057,"user_tz":180,"elapsed":1228,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# function to train the model\n","def train():\n","  \n","  model.train()\n","#   i=0\n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save model predictions\n","  total_preds=[]\n","  \n","  # iterate over batches\n","  for step,batch in enumerate(train_dataloader):\n","    # print(i)\n","    # progress update after every 50 batches.\n","    if step % 10 == 0 and not step == 0:\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [r.to(device) for r in batch]\n"," \n","    sent_id, mask, labels = batch\n","\n","    # clear previously calculated gradients \n","    model.zero_grad()        \n","\n","    # get model predictions for the current batch\n","    preds = model(sent_id, mask,'train')\n","\n","    # compute the loss between actual and predicted values\n","    loss = cross_entropy(preds, labels)\n","\n","    # add on to the total loss\n","    total_loss = total_loss + loss.item()\n","\n","    # backward pass to calculate the gradients\n","    loss.backward()\n","    total_steps = len(train_dataloader) * epochs\n","    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                        num_warmup_steps = 0, # Default value in run_glue.py\n","                                                        num_training_steps = total_steps)\n","    # update parameters\n","    optimizer.step()\n","    scheduler.step()\n","    # model predictions are stored on GPU. So, push it to CPU\n","    preds=preds.detach().cpu().numpy()\n","\n","    # append the model predictions\n","    total_preds.append(preds)\n","    # i+=1\n","  # compute the training loss of the epoch\n","  avg_loss = total_loss / len(train_dataloader)\n","  \n","  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  #returns the loss and predictions\n","  return avg_loss, total_preds"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"oOW3mvSig6vy","executionInfo":{"status":"ok","timestamp":1619791061808,"user_tz":180,"elapsed":1111,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["# function for evaluating the model\n","def evaluate():\n","  \n","  print(\"\\nEvaluating...\")\n","  \n","  # deactivate dropout layers\n","  model.eval()\n","#   i=0  \n","  total_loss, total_accuracy = 0, 0\n","  \n","  # empty list to save the model predictions\n","  total_preds = []\n","\n","  # iterate over batches\n","  for step,batch in enumerate(val_dataloader):\n","    # print(i)\n","    # Progress update every 50 batches.\n","    if step % 10 == 0 and not step == 0:\n","      \n","      # Calculate elapsed time in minutes.\n","    #   elapsed = format_time(time.time() - t0)\n","            \n","      # Report progress.\n","      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","\n","    # push the batch to gpu\n","    batch = [t.to(device) for t in batch]\n","\n","    sent_id, mask, labels = batch\n","\n","    # deactivate autograd\n","    with torch.no_grad():\n","    #   print(\"val_loop:\",i)\n","      # model predictions\n","      preds = model(sent_id, mask,'evaluate')\n","\n","      # compute the validation loss between actual and predicted values\n","      loss = cross_entropy(preds,labels)\n","\n","      total_loss = total_loss + loss.item()\n","\n","      preds = preds.detach().cpu().numpy()\n","\n","      total_preds.append(preds)\n","    # i+=1\n","  # compute the validation loss of the epoch\n","  avg_loss = total_loss / len(val_dataloader) \n","\n","  # reshape the predictions in form of (number of samples, no. of classes)\n","  total_preds  = np.concatenate(total_preds, axis=0)\n","\n","  return avg_loss, total_preds"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zcqb-NgbO4Vq","executionInfo":{"status":"ok","timestamp":1619791062118,"user_tz":180,"elapsed":403,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}}},"source":["random_seeds=[68,96,20,53,91,7,42,14,24,67]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"dxn9T5xp4Cgx","executionInfo":{"status":"ok","timestamp":1619791063276,"user_tz":180,"elapsed":768,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"fda6c0e6-3fdf-4fbe-f436-8d9ffc0c6c7b"},"source":["dev_test"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mwe</th>\n","      <th>label</th>\n","      <th>sentence</th>\n","      <th>par</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>736</th>\n","      <td>второй дом</td>\n","      <td>0</td>\n","      <td>рга\"бани пешком, останавливаться не разрешалос...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>334</th>\n","      <td>на высоте</td>\n","      <td>0</td>\n","      <td>\"Си-Эн Тауэр\"Башня Си-Эн в  \"Торонто\"Торонто ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>не за горами</td>\n","      <td>1</td>\n","      <td>Старый  \"сёгун\"сёгун посылает убийц к своему б...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>522</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>В то же время Люк Пламондон снова приглашает Б...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>405</th>\n","      <td>поставить точку</td>\n","      <td>1</td>\n","      <td>опубликованных ранее Ватиканом. В отчёте комис...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>371</th>\n","      <td>последняя капля</td>\n","      <td>1</td>\n","      <td>В  \"1984 год\"1984 году из  (подавленный эффект...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>587</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>\"17 марта\"17 марта  \"2011 год\"2011 года назна...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>еле дышит</td>\n","      <td>0</td>\n","      <td>а сам ждёт в засаде с занесённым утюгом. Джер...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>568</th>\n","      <td>с блеском</td>\n","      <td>1</td>\n","      <td>нетерпимости проведён в государственный строй ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>744</th>\n","      <td>второй дом</td>\n","      <td>0</td>\n","      <td>м, в котором живет и по сей день. В  \"1993 год...</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>194 rows × 4 columns</p>\n","</div>"],"text/plain":["                 mwe  ...  par\n","736       второй дом  ...    2\n","334        на высоте  ...    2\n","361     не за горами  ...    3\n","522        с блеском  ...    2\n","405  поставить точку  ...    3\n","..               ...  ...  ...\n","371  последняя капля  ...    2\n","587        с блеском  ...    2\n","138        еле дышит  ...    2\n","568        с блеском  ...    2\n","744       второй дом  ...    3\n","\n","[194 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589,"referenced_widgets":["1372baa745904245b09d8018aaf7cf30","be7e4ac4e5f546b0af3210c8abed2807","bc0023925f80467e96dda4deb5026573","c80205149f7c457981ac05d93834d2f2","8516c7266f8841a096d61eece52a6a7e","89fb2f1ab5c245908c53786beb97673e","1f544041d87549c2a4e85d5b413578c4","bef18cc12a194fe39799264692378d21","d68fca4be39b46e1a5a46e1caaac71ca","f3cc79fda75d4e30b63cb86cff75a4eb","c6640dcae7604befb2a184bb22f81de3","2f1a9865e3f1408e836e7b9f5b754a6c","db05771ee82348a188f9f7c798c2f878","38eb6ba3c3624081a4e4c634dc9008d5","35854e2516e841aca52cae7bf3b9dedb","3cd41446e56047b883f9b3f9b1c2c929","50a1dfd2dfb14624b8b823c6d46d8c56","ba2e2559ccd24e588a537e2163412e16","c70750e71a764678afd1be2db91ea6bd","b0f2a5c0f2dd4e8aa73ef809ddbf25f5","f94bce417e634843ad6ca532a58061e6","fd85e4abc7d64f2b92f8aa2e0704c313","e166a1bb7c88464fae8808e6aefa6c94","51ad507babb54614b68108fc4b2665f4"]},"id":"Z3eI0_m3dqFL","executionInfo":{"status":"error","timestamp":1619791176869,"user_tz":180,"elapsed":79118,"user":{"displayName":"Samin Fakharian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFi1gkXRQ0jRQiMMLiILHLVk8ulyIY9ehIbVkQ5g=s64","userId":"00770828924006406210"}},"outputId":"41d4b1d4-8123-4fdd-cbfd-14290fef2e45"},"source":["################################################################################\n","#################################### all together ##############################\n","################################################################################\n","temp_train=pd.DataFrame()\n","temp_validation=pd.DataFrame()\n","train_loss=[]\n","lr_clf_scores_dict={}\n","svc_clf_scores_dict={}\n","avg_acc=[]\n","val_result = []\n","by_expression=pd.DataFrame(columns=['rand_var','file','mwe','label','prediction'])\n","# learning_rate_range=[2e-5,3e-5,5e-5]\n","# epoch_range=[2,3,4]\n","# batch_size_range=[8,16,32]\n","\n","learning_rate_range=[3e-5]\n","epoch_range=[4]\n","batch_size_range=[8]\n","\n","i=0\n","run=0\n","final_result_df=pd.DataFrame()\n","final_result_df_le=pd.DataFrame()\n","random_seeds=[68,96,20,53,91,72,42,14,24,67]\n","# random_seeds=[42]\n","\n","for rand_var in random_seeds:\n","    for er in epoch_range:\n","        for lrr in learning_rate_range:\n","          for bsr in batch_size_range:\n","            for ds in range(0,10):\n","                print(run)\n","                run+=1\n","                print(\"-------------------------------------------------------\")\n","                print(\"Start processing for: \",ds)\n","                temp_train=dev_train#[dev_train.fileName==ds]\n","                temp_test=dev_test#[dev_test.fileName==ds]\n","                \n","                seed_value = rand_var\n","\n","                # 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n","                import os\n","                os.environ['PYTHONHASHSEED']=str(seed_value)\n","                # 2. Set `python` built-in pseudo-random generator at a fixed value\n","                import random\n","                random.seed(seed_value)\n","                # 3. Set `numpy` pseudo-random generator at a fixed value\n","                import numpy as np\n","                np.random.seed(seed_value)\n","                import torch\n","                torch.manual_seed(seed_value)\n","                torch.cuda.manual_seed_all(seed_value)\n","                torch.backends.cudnn.deterministic = True\n","                torch.backends.cudnn.benchmark = False\n","\n","\n","                # bert = AutoModel.from_pretrained('bert-base-uncased')\n","                bert = BertModel.from_pretrained('bert-base-multilingual-cased')\n","                # Load the BERT tokenizer\n","                tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n","                # get length of all the messages in the train set\n","                seq_len = [len(i.split()) for i in dev_train['sentence']]\n","                # pd.Series(seq_len).hist(bins = 30)\n","                max_seq_len = 0\n","                max_len = max_seq_len\n","                # For every sentence...\n","                for sent in temp_train['sentence']:\n","                    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","                    # print(sent)\n","                    train_input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","                    # print(train_input_ids)\n","                    # Update the maximum sentence length.\n","                    max_seq_len = max(max_seq_len, len(train_input_ids))\n","                \n","                max_seq_len=256\n","                train_text, val_text, train_labels, val_labels = train_test_split(temp_train['sentence'], temp_train['label'], \n","                                                                        random_state=2018, \n","                                                                        test_size=0.2, \n","                                                                        stratify=temp_train['label'])\n","                print(len(train_text))\n","                # we will use temp_text and temp_labels to create validation and test set\n","                test_text =temp_test['sentence']\n","                test_labels =temp_test['label']\n","                # tokenize and encode sequences in the training set\n","                tokens_train = tokenizer.batch_encode_plus(\n","                    train_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","                # print(tokens_train)\n","                # tokenize and encode sequences in the validation set\n","                tokens_val = tokenizer.batch_encode_plus(\n","                    val_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","\n","                # tokenize and encode sequences in the test set\n","                tokens_test = tokenizer.batch_encode_plus(\n","                    test_text.tolist(),\n","                    max_length = max_seq_len,\n","                    pad_to_max_length=True,\n","                    truncation=True,\n","                    return_token_type_ids=False\n","                )\n","                # for train set\n","                train_seq = torch.tensor(tokens_train['input_ids'])\n","                train_mask = torch.tensor(tokens_train['attention_mask'])\n","                train_y = torch.tensor(train_labels.tolist())\n","\n","                # for validation set\n","                val_seq = torch.tensor(tokens_val['input_ids'])\n","                val_mask = torch.tensor(tokens_val['attention_mask'])\n","                val_y = torch.tensor(val_labels.tolist())\n","\n","                # for test set\n","                test_seq = torch.tensor(tokens_test['input_ids'])\n","                test_mask = torch.tensor(tokens_test['attention_mask'])\n","                test_y = torch.tensor(test_labels.tolist())\n","\n","                #define a batch size\n","                batch_size = bsr\n","                # wrap tensors\n","                train_data = TensorDataset(train_seq, train_mask, train_y)\n","                # sampler for sampling the data during training\n","                train_sampler = RandomSampler(train_data)\n","                # dataLoader for train set\n","                train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","                # wrap tensors\n","                val_data = TensorDataset(val_seq, val_mask, val_y)\n","                # sampler for sampling the data during training\n","                val_sampler = SequentialSampler(val_data)\n","                # dataLoader for validation set\n","                val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n","                # CF_arr=torch.tensor(temp_train.isCanon.to_numpy())\n","                # CF_arr=torch.reshape(CF_arr,(-1,1))\n","                # CF_arr=CF_arr.to(device)\n","                # CF_test_arr=torch.tensor(temp_test.isCanon.to_numpy())\n","                # CF_test_arr=torch.reshape(CF_test_arr,(-1,1))\n","                # CF_test_arr=CF_arr.to(device)\n","\n","                training_stats = []\n","                training_stats_le = []\n","                # pass the pre-trained BERT to our define architecture\n","                model = Classifier(bert)\n","                # push the model to GPU\n","                model = model.to(device)\n","                # optimizer from hugging face transformer\n","                # define the optimizer\n","                optimizer = AdamW(model.parameters(), lr = lrr)\n","                #compute the class weights\n","                class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n","                # convert class weights to tensor\n","                weights= torch.tensor(class_wts,dtype=torch.float)\n","                weights = weights.to(device)\n","\n","                # loss function\n","                cross_entropy  = nn.NLLLoss(weight=weights) \n","\n","                # number of training epochs\n","                epochs = er\n","                # set initial loss to infinite\n","                best_valid_loss = float('inf')\n","\n","                # empty lists to store training and validation loss of each epoch\n","                train_losses=[]\n","                valid_losses=[]\n","\n","                #for each epoch\n","                for epoch in range(epochs):\n","                    \n","                    print('\\nEpoch {:}/{:}'.format(epoch + 1, epochs))\n","                    \n","                    #train model\n","                    train_loss, _ = train()\n","                    \n","                    #evaluate model\n","                    valid_loss, _ = evaluate()\n","                    \n","                    #save the best model\n","                    if valid_loss < best_valid_loss:\n","                        best_valid_loss = valid_loss\n","                        torch.save(model.state_dict(), 'saved_weights.pt')\n","                    \n","                    # append training and validation loss\n","                    train_losses.append(train_loss)\n","                    valid_losses.append(valid_loss)\n","                    print(f'\\nTraining Loss: {train_loss:10.4f}')\n","                    print(f'Validation Loss: {valid_loss:10.4f}')\n","                    \n","                # get predictions for test data\n","                with torch.no_grad():\n","                    preds = model(test_seq.to(device), test_mask.to(device),'test')\n","                    preds = preds.detach().cpu().numpy()\n","                # model's performance\n","                preds = np.argmax(preds, axis = 1)\n","\n","                # print(classification_report(test_y, preds))\n","                total_eval_accuracy_num = 0\n","                total_eval_accuracy = 0\n","                total_eval_accuracy = flat_accuracy(preds, test_y)\n","                total_eval_accuracy_num = flat_accuracy_num(preds, test_y)\n","                print(\"Number of True Prediction: {0:10.4f}\".format(total_eval_accuracy_num))\n","                # avg_val_accuracy = total_eval_accuracy / len(test_y)\n","                print(\"Accuracy: {0:10.4f}\".format(total_eval_accuracy))\n","                \n","                # val_result.append((rand_var,total_eval_accuracy, total_eval_accuracy_num, len(test_y),ds, lrr, er, bsr))\n","                quick_temp=pd.DataFrame(columns=['rand_var','file','mwe','label','prediction'])\n","                quick_temp['rand_var']=[rand_var]*len(preds)\n","                quick_temp['file']=[ds]*len(preds)                \n","                quick_temp['mwe']=temp_test['mwe'].tolist()\n","                quick_temp['label']=temp_test['label'].tolist()\n","                quick_temp['prediction']=preds\n","                by_expression=by_expression.append(quick_temp)\n","\n","                TN = 0\n","                FN = 0\n","                TP = 0\n","                FP = 0       \n","                CM = confusion_matrix(test_y, preds)\n","                report= classification_report(test_y, preds, digits=3,output_dict=True)\n","                df = pd.DataFrame(report).transpose()\n","\n","                TN = CM[0][0]\n","                FN = CM[1][0]\n","                TP = CM[1][1]\n","                FP = CM[0][1]\n","\n","                if ((TP+FP) == 0):\n","                    precision = 0.0\n","                else:\n","                    precision=TP/(TP+FP)\n","                if ((TP+FN) == 0):\n","                    recall = 0.0\n","                else:\n","                    recall=TP/(TP+FN)\n","                if (precision+recall > 0 ):\n","                    f1 = (2.0*precision*recall)/(precision+recall)\n","                else:\n","                    f1 = 0.0\n","\n","                precision_0=report['0']['precision']\n","                recall_0=report['0']['recall']\n","                f1_0=report['0']['f1-score']\n","                support_0=report['0']['support']\n","                precision_1=report['1']['precision']\n","                recall_1=report['1']['recall']\n","                f1_1=report['1']['f1-score']\n","                support_1=report['1']['support']\n","                macro_avg_f1=report['macro avg']['f1-score']\n","                macro_avg_precision=report['macro avg']['precision']\n","                macro_avg_recall=report['macro avg']['recall']\n","                macro_avg_support=report['macro avg']['support']\n","                weighted_avg_f1=report['weighted avg']['f1-score']\n","                weighted_avg_precision=report['weighted avg']['precision']\n","                weighted_avg_recall=report['weighted avg']['recall']\n","                weighted_avg_support=report['weighted avg']['support']\n","                val_result.append((rand_var,total_eval_accuracy, total_eval_accuracy_num, len(test_y),\n","                                    TN,FN,TP,FP,\n","                                    precision_0,recall_0,f1_0,support_0,\n","                                    precision_1,recall_1,f1_1,support_1,\n","                                    macro_avg_f1,macro_avg_precision,macro_avg_recall,macro_avg_support,\n","                                    weighted_avg_f1,weighted_avg_precision,weighted_avg_recall,weighted_avg_support,\n","                                    ds, lrr, er, bsr))\n","                print('DONE.')\n","validation_df=pd.DataFrame(val_result,columns=['rand_var','accuracy', 'true_labels', 'all_labels',\n","                                               'TN','FN','TP','FP',\n","                                                'precision_literal','recall_literal','f1_literal','support_literal',\n","                                                'precision_idiomatic','recall_idiomatic','f1_idiomatic','support_idiomatic',\n","                                                'macro_avg_f1','macro_avg_precision','macro_avg_recall','macro_avg_support',\n","                                                'weighted_avg_f1','weighted_avg_precision','weighted_avg_recall','weighted_avg_support',\n","                                               'file', 'lr', 'e', 'b'])\n","\n","validation_df.to_excel('BERT-AE-E-Wiki-mbert-randomseeds-TEST.xlsx',index=False)\n","files.download('BERT-AE-E-Wiki-mbert-randomseeds-TEST.xlsx')\n","\n","# expression_df=pd.DataFrame(by_expression,columns=['mwe','label', 'prediction'])\n","# by_expression.to_excel('BERT-AE-W-Wiki-Expression-mbert.xlsx',index=False)\n","# files.download('BERT-AE-W-Wiki-Expression-mbert.xlsx') "],"execution_count":18,"outputs":[{"output_type":"stream","text":["0\n","-------------------------------------------------------\n","Start processing for:  0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1372baa745904245b09d8018aaf7cf30","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d68fca4be39b46e1a5a46e1caaac71ca","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50a1dfd2dfb14624b8b823c6d46d8c56","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","464\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-30fdabfc80b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;31m# push the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;31m# optimizer from hugging face transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;31m# define the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"nc5Xa7KVMMdT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-LgzYXdzVoAq"},"source":["# from sklearn.manifold import TSNE\n","\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# dev_train=test_train\n","# dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(5, 3,figsize=(25,30))\n","# fig.suptitle('MWEs')\n","# i=0\n","# t= TSNE(learning_rate=20)\n","# mwe_list=temp_test.mwe.unique()\n","# palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# for m,ax in zip(mwe_list,axes.flatten()[:15]):\n","#     df=pd.DataFrame()\n","#     df['label']=temp_test[temp_test.mwe==m]['label']\n","#     tsne_features=t.fit_transform(hidden_data[i])\n","#     df['x']=tsne_features[:,0]\n","#     df['y']=tsne_features[:,1]\n","#     sns.scatterplot(ax=ax, x=\"x\",y=\"y\",hue='label',data=df,palette=palette).set_title(m,fontsize=16)\n","#     i+=1\n","\n","# plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37Wmhxu4dUB_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZ1H6Xy7qal2"},"source":["# from sklearn.manifold import TSNE\n","# all_hidden_data=[]\n","# for i in range(0,10):\n","#     for j in range(len(hidden_data[i])):\n","#         all_hidden_data.append(hidden_data[i][j].tolist())\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# # test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# # test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# # dev_train=test_train\n","# # dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(1, 1,figsize=(15,15))\n","# t= TSNE(learning_rate=50)\n","# mwe_list=temp_test.mwe.unique()\n","# palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# df=pd.DataFrame()\n","# df['label']=temp_test['label']\n","# tsne_features=t.fit_transform(all_hidden_data)\n","# df['x']=tsne_features[:,0]\n","# df['y']=tsne_features[:,1]\n","# sns.scatterplot(ax= axes,x=\"x\",y=\"y\",hue='label',data=df,palette=palette).set_title('AllData',fontsize=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFoO9jW4qUR_"},"source":["# from sklearn.manifold import TSNE\n","# all_hidden_data=[]\n","# for i in range(0,10):\n","#     for j in range(len(hidden_data[i])):\n","#         all_hidden_data.append(hidden_data[i][j].tolist())\n","# dev_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Train.csv')\n","# dev_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/DEV-Test.csv')\n","# test_train=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Train.csv')\n","# test_test=pd.read_csv('./drive/My Drive/Colab Notebooks/dataset/TEST-Test.csv')\n","# dev_train=test_train\n","# dev_test=test_test\n","# temp_test=dev_test\n","# temp_test['label'] = dev_test.label.map({'L':'Literal', 'I':'Idiomatic'})\n","\n","# fig, axes = plt.subplots(1, 1,figsize=(15,15))\n","# t= TSNE(learning_rate=50)\n","# mwe_list=temp_test.mwe.unique()\n","# # palette ={\"Idiomatic\": \"blue\", \"Literal\": \"red\"}\n","# df=pd.DataFrame()\n","# df['label']=temp_test['label']\n","# df['mwe']=temp_test['mwe']\n","\n","# tsne_features=t.fit_transform(all_hidden_data)\n","# df['x']=tsne_features[:,0]\n","# df['y']=tsne_features[:,1]\n","# sns.scatterplot(ax= axes,x=\"x\",y=\"y\",hue='mwe',data=df).set_title('AllData',fontsize=16)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n7WMFzDYtLoO"},"source":[""],"execution_count":null,"outputs":[]}]}